{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical Questions"
      ],
      "metadata": {
        "id": "_bRtW_kuz2By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1:  Can we use Bagging for regression problems?\n",
        "\n",
        "A1:  Yes, bagging can be used for regression problems. In regression tasks, bagging works by creating multiple bootstrap samples from the original dataset and training separate models, usually decision trees, on each sample. The final prediction is obtained by taking the average of the predictions from all models. This approach helps reduce variance, improve stability, and prevent overfitting, making it very effective for regression problems.\n",
        "\n",
        "\n",
        "\n",
        "Q2:  What is the difference between multiple model training and single model training?\n",
        "\n",
        "A2:  Single model training involves training only one model on the entire dataset, such as a single decision tree or linear regression model. Its performance depends entirely on that one model, which may suffer from high bias or high variance. On the other hand, multiple model training, also known as ensemble learning, involves training several models and combining their predictions through methods like averaging or voting. This approach generally improves accuracy, reduces overfitting, and provides better generalization compared to a single model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Q3:  Explain the concept of feature randomness in Random Forest.\n",
        "\n",
        "A3:  Feature randomness in Random Forest refers to the process of selecting a random subset of features at each split while constructing individual decision trees. Instead of considering all available features for splitting, the algorithm randomly chooses a limited number of features and selects the best split among them. This increases diversity among the trees, reduces correlation between them, and improves the overall performance of the model while minimizing overfitting.\n",
        "\n",
        "Q4:  What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "A4:  The Out-of-Bag (OOB) score is an internal validation technique used in Random Forest. During bootstrap sampling, some data points are not included in the training sample for a particular tree. These unused data points are called out-of-bag samples. The model uses these OOB samples to test the performance of the corresponding tree. The overall OOB score provides an estimate of the model’s accuracy without requiring a separate validation dataset.\n",
        "\n",
        "\n",
        "\n",
        "Q5:  How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "A5:  Feature importance in a Random Forest model can be measured using methods such as Mean Decrease in Impurity and Permutation Importance. Mean Decrease in Impurity calculates how much each feature contributes to reducing impurity (like Gini index or entropy) across all trees in the forest. Permutation Importance measures the drop in model performance when the values of a particular feature are randomly shuffled. If the performance decreases significantly, the feature is considered important. These methods help identify which features have the greatest impact on predictions.\n",
        "\n",
        "Q6: Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "A6: A Bagging Classifier works on the principle of bootstrap aggregating, where multiple subsets of data are created from the original dataset using random sampling with replacement. Each subset is used to train a separate base classifier, commonly a decision tree. Since each model is trained on slightly different data, they learn different patterns. During prediction, all trained classifiers give their outputs, and the final prediction is decided by majority voting. This approach reduces variance, improves stability, and minimizes overfitting compared to a single classifier.\n",
        "\n",
        "Q7: How do you evaluate a Bagging Classifier’s performance?\n",
        "\n",
        "A7: The performance of a Bagging Classifier can be evaluated using standard classification metrics such as accuracy, precision, recall, F1-score, and ROC-AUC score. A confusion matrix is also useful to analyze true positives, true negatives, false positives, and false negatives. Additionally, the Out-of-Bag (OOB) score can be used as an internal validation method when bootstrap sampling is applied. Cross-validation techniques can further ensure that the model performs well on unseen data and provides reliable results.\n",
        "\n",
        "Q8: How does a Bagging Regressor work?\n",
        "\n",
        "A8:  A Bagging Regressor works similarly to a Bagging Classifier but is used for regression tasks where the output is continuous. It creates multiple bootstrap samples from the original dataset and trains separate regression models, usually decision tree regressors, on each sample. Each model produces a numerical prediction for a given input. The final output is calculated by taking the average of all individual predictions. This averaging process reduces variance, improves model stability, and enhances overall prediction accuracy.\n",
        "\n",
        "Q9: What is the main advantage of ensemble techniques?\n",
        "\n",
        "A9: The main advantage of ensemble techniques is that they combine the strengths of multiple models to produce better performance than a single model. By aggregating predictions, ensemble methods reduce variance and bias, improve accuracy, and provide better generalization on unseen data. They are particularly useful in complex problems where a single model may not capture all patterns effectively. Ensemble methods also make the final prediction more robust and reliable.\n",
        "\n",
        "Q10: What is the main challenge of ensemble methods?\n",
        "\n",
        "A10: The main challenge of ensemble methods is their increased computational complexity and resource requirements. Training multiple models requires more processing time, memory, and computational power compared to a single model. Additionally, ensemble models can be difficult to interpret because the final prediction is based on the combined output of many models. This lack of transparency can make it harder to explain the model’s decision-making process.\n",
        "\n",
        "Q11: Explain the key idea behind ensemble techniques.\n",
        "\n",
        "A11: The key idea behind ensemble techniques is to combine multiple models to produce a better and more reliable prediction than a single model. Instead of depending on one model, ensemble methods aggregate the outputs of several models using techniques like averaging or voting. This combination helps reduce errors caused by bias or variance and improves overall accuracy and stability of the model.\n",
        "\n",
        "Q12: What is a Random Forest Classifier?\n",
        "\n",
        "A12: A Random Forest Classifier is an ensemble learning method that builds multiple decision trees using bootstrap samples of the dataset and random subsets of features at each split. Each tree independently predicts the class label, and the final output is determined by majority voting among all trees. It reduces overfitting, improves accuracy, and provides better generalization compared to a single decision tree.\n",
        "\n",
        "Q13: What are the main types of ensemble techniques?\n",
        "\n",
        "A13: The main types of ensemble techniques are Bagging, Boosting, and Stacking. Bagging builds multiple models independently and combines their predictions, mainly to reduce variance. Boosting builds models sequentially, where each new model focuses on correcting the errors of the previous one, mainly to reduce bias. Stacking combines predictions from multiple different models using a meta-model to improve overall performance.\n",
        "\n",
        "Q14: What is ensemble learning in machine learning?\n",
        "\n",
        "A14: Ensemble learning is a machine learning approach in which multiple models are trained and combined to solve the same problem. The main objective is to improve prediction accuracy and robustness by aggregating the outputs of different models. Ensemble learning helps achieve better performance than individual models by reducing bias, variance, or both.\n",
        "\n",
        "Q15: When should we avoid using ensemble methods?\n",
        "\n",
        "A15: Ensemble methods should be avoided when computational resources are limited, as they require more memory and processing power. They may also not be suitable when model interpretability is very important, since ensemble models are harder to explain. Additionally, if the dataset is very small or simple, a single well-tuned model may perform sufficiently without the added complexity of an ensemble.\n",
        "\n",
        "Q16: How does Bagging help in reducing overfitting?\n",
        "\n",
        "A16: Bagging reduces overfitting by training multiple models on different bootstrap samples of the dataset and then combining their predictions. Since each model sees slightly different data, they learn different patterns. Averaging or voting among these models reduces variance and prevents the final model from relying too heavily on noise or specific patterns in the training data.\n",
        "\n",
        "Q17: Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "A17: Random Forest is better than a single Decision Tree because it reduces overfitting and improves generalization. A single decision tree can easily overfit the training data, especially if it is deep. Random Forest builds multiple trees using random samples of data and features, and combines their predictions. This reduces variance, increases stability, and generally results in higher accuracy.\n",
        "\n",
        "Q18: What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "A18: Bootstrap sampling plays a crucial role in Bagging by creating multiple different training datasets from the original dataset through random sampling with replacement. Each model is trained on a different bootstrap sample, which introduces diversity among models. This diversity helps in reducing variance and improving the overall performance and robustness of the ensemble.\n",
        "\n",
        "Q19: What are some real-world applications of ensemble techniques?\n",
        "\n",
        "A19: Ensemble techniques are widely used in real-world applications such as fraud detection, credit risk assessment, medical diagnosis, stock market prediction, recommendation systems, and image classification. They are particularly useful in complex problems where high accuracy and reliability are required. Many winning solutions in machine learning competitions also use ensemble methods.\n",
        "\n",
        "Q20: What is the difference between Bagging and Boosting?\n",
        "\n",
        "A20: Bagging and Boosting are both ensemble techniques but differ in their approach. Bagging builds multiple models independently using bootstrap samples and combines their predictions through averaging or voting to reduce variance. Boosting builds models sequentially, where each new model focuses on correcting the mistakes of the previous one, mainly to reduce bias. Bagging models can be trained in parallel, while Boosting models depend on the previous model’s performance.\n"
      ],
      "metadata": {
        "id": "ahhL-HgL0ADm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions\n"
      ],
      "metadata": {
        "id": "NsWHrpL22JGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21.  Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ],
      "metadata": {
        "id": "OuniarDz2Nfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDr-_Go-yjZ1",
        "outputId": "b7e42a97-c815-4436-8f75-dbe5a783f90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Bagging Classifier with Decision Tree\n",
        "model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22.  Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "nLV4YOEG3FAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Bagging Regressor with Decision Tree\n",
        "model = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD4h-Ojt27XB",
        "outputId": "5c01192d-7ff4-4d49-bf13-31ac9d980585"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.25787382250585034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
      ],
      "metadata": {
        "id": "N6t4xT7q3OWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "print(\"Feature Importance Scores:\")\n",
        "for feature, importance in zip(data.feature_names, model.feature_importances_):\n",
        "    print(f\"{feature}: {importance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL8fKhZg3KR3",
        "outputId": "8533e605-7d9e-442d-f9c6-675aee8484f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "mean radius: 0.032311888273301004\n",
            "mean texture: 0.011063901250175845\n",
            "mean perimeter: 0.060092333477412795\n",
            "mean area: 0.05381045367561502\n",
            "mean smoothness: 0.006223358550035776\n",
            "mean compactness: 0.009215659698391042\n",
            "mean concavity: 0.08055701642634591\n",
            "mean concave points: 0.1419344436315119\n",
            "mean symmetry: 0.003278068988046974\n",
            "mean fractal dimension: 0.003140276443878005\n",
            "radius error: 0.016434957577357797\n",
            "texture error: 0.003171913625550393\n",
            "perimeter error: 0.011769755537440448\n",
            "area error: 0.029538418256883636\n",
            "smoothness error: 0.005880791914760226\n",
            "compactness error: 0.004596378662668866\n",
            "concavity error: 0.005815899489496524\n",
            "concave points error: 0.0033823220710919844\n",
            "symmetry error: 0.0040007728493448805\n",
            "fractal dimension error: 0.007134569189458313\n",
            "worst radius: 0.07797474929691814\n",
            "worst texture: 0.018785671163890155\n",
            "worst perimeter: 0.07429212194132524\n",
            "worst area: 0.11821685833472201\n",
            "worst smoothness: 0.011769174205977244\n",
            "worst compactness: 0.017539085585610643\n",
            "worst concavity: 0.04107957505964944\n",
            "worst concave points: 0.12713637963171595\n",
            "worst symmetry: 0.01292944626553497\n",
            "worst fractal dimension: 0.006923758925888881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24.  Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ],
      "metadata": {
        "id": "0ix_XWG43WoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize models\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train models\n",
        "rf_model.fit(X_train, y_train)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Random Forest Regressor:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, rf_pred))\n",
        "print(\"R2 Score:\", r2_score(y_test, rf_pred))\n",
        "\n",
        "print(\"\\nDecision Tree Regressor:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, dt_pred))\n",
        "print(\"R2 Score:\", r2_score(y_test, dt_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cnhFeWJ3UGC",
        "outputId": "38e7c73a-edfc-4cb8-c2e0-ceca0984dfa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor:\n",
            "MSE: 0.25650512920799395\n",
            "R2 Score: 0.8045734925119942\n",
            "\n",
            "Decision Tree Regressor:\n",
            "MSE: 0.5280096503174904\n",
            "R2 Score: 0.5977192261218356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
      ],
      "metadata": {
        "id": "0GcZfG3i3fYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Create Random Forest with OOB enabled\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    oob_score=True,\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print OOB Score\n",
        "print(\"OOB Score:\", model.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX3v_7MU3eTO",
        "outputId": "4ade4afa-0426-4403-ff1e-377e6d74f550"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9533333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ],
      "metadata": {
        "id": "rHN9sYJU3yJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Bagging Classifier with SVM base estimator\n",
        "model = BaggingClassifier(\n",
        "    estimator=SVC(),\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz2kA5N13rRj",
        "outputId": "736043c4-ed75-47c5-81bf-3860fe631042"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ],
      "metadata": {
        "id": "VerWZjgt35Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Different numbers of trees\n",
        "tree_counts = [10, 50, 100, 200]\n",
        "\n",
        "for n in tree_counts:\n",
        "    model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Number of Trees: {n}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7voDW-o732ah",
        "outputId": "ae895947-c2f8-44e1-9f7e-e3583d0fc224"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Trees: 10, Accuracy: 1.0\n",
            "Number of Trees: 50, Accuracy: 1.0\n",
            "Number of Trees: 100, Accuracy: 1.0\n",
            "Number of Trees: 200, Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ],
      "metadata": {
        "id": "qEUQsV6E4B1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create Bagging Classifier with Logistic Regression\n",
        "model = BaggingClassifier(\n",
        "    estimator=LogisticRegression(max_iter=5000),\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate AUC Score\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "print(\"AUC Score:\", auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQoTx9NG4BFn",
        "outputId": "bebde7db-395a-43ec-8c6b-65a001158456"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 0.9973544973544973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29.  Train a Random Forest Regressor and analyze feature importance scores."
      ],
      "metadata": {
        "id": "qTMgSilb4ODZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance\n",
        "print(\"Feature Importance Scores:\")\n",
        "for name, score in zip(data.feature_names, model.feature_importances_):\n",
        "    print(name, \":\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnJ5Jigb4K6u",
        "outputId": "15821f3b-c872-45a1-c94a-ed61e029067f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "MedInc : 0.5260109842753186\n",
            "HouseAge : 0.05465403794347876\n",
            "AveRooms : 0.04718824566150784\n",
            "AveBedrms : 0.02999453307261222\n",
            "Population : 0.031721806473035755\n",
            "AveOccup : 0.13821986994513355\n",
            "Latitude : 0.08608613054646935\n",
            "Longitude : 0.08612439208244402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ],
      "metadata": {
        "id": "xcYdv_Ok4YXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Model\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train models\n",
        "bagging_model.fit(X_train, y_train)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "bagging_pred = bagging_model.predict(X_test)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Accuracy comparison\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bagging_pred))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpea9-CA4kWy",
        "outputId": "856a9281-ab65-47f7-f4a2-89c5fabd433d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
      ],
      "metadata": {
        "id": "nAEHTzKM4l8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Define model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK69AUcZ4lDA",
        "outputId": "884f3e06-df7c-433b-8ae3-2c33142d258d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance."
      ],
      "metadata": {
        "id": "lUx3VD5D4s5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Different numbers of base estimators\n",
        "estimators_list = [10, 50, 100, 200]\n",
        "\n",
        "for n in estimators_list:\n",
        "    model = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(),\n",
        "        n_estimators=n,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Estimators: {n}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"R2 Score:\", r2)\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAS6Yu244u4S",
        "outputId": "50af1927-c5ab-4415-86c9-9019da087a42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimators: 10\n",
            "MSE: 0.28623579601385674\n",
            "R2 Score: 0.7819222480823047\n",
            "------------------------------\n",
            "Estimators: 50\n",
            "MSE: 0.25787382250585034\n",
            "R2 Score: 0.8035307104364535\n",
            "------------------------------\n",
            "Estimators: 100\n",
            "MSE: 0.2568358813508342\n",
            "R2 Score: 0.8043214985798688\n",
            "------------------------------\n",
            "Estimators: 200\n",
            "MSE: 0.2541650541215747\n",
            "R2 Score: 0.8063563523823236\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q33. Train a Random Forest Classifier and analyze misclassified samples."
      ],
      "metadata": {
        "id": "mX2RZxim4vwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Analyze Misclassified Samples\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "\n",
        "print(\"\\nNumber of Misclassified Samples:\", len(misclassified_indices))\n",
        "\n",
        "for idx in misclassified_indices:\n",
        "    print(f\"Index: {idx}, Actual: {y_test[idx]}, Predicted: {y_pred[idx]}, Features: {X_test[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nKiAClb47BO",
        "outputId": "31dfa4c8-3f27-4d72-dd6a-0d15834ef03e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n",
            "\n",
            "Number of Misclassified Samples: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
      ],
      "metadata": {
        "id": "J7fSQav4484W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Single Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Bagging Classifier\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bag_pred = bagging_model.predict(X_test)\n",
        "\n",
        "# Compare Accuracy\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
        "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, bag_pred))\n",
        "\n",
        "# Optional: Detailed Report\n",
        "print(\"\\nDecision Tree Report:\\n\", classification_report(y_test, dt_pred))\n",
        "print(\"Bagging Classifier Report:\\n\", classification_report(y_test, bag_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQ5sA9-4-Et",
        "outputId": "99783673-92db-4d2c-fa12-d80c09c120ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 1.0\n",
            "Bagging Classifier Accuracy: 1.0\n",
            "\n",
            "Decision Tree Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "Bagging Classifier Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q35. Train a Random Forest Classifier and visualize the confusion matrix."
      ],
      "metadata": {
        "id": "wK5qEoZn4-kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
        "disp.plot()\n",
        "\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "qfBmu5LV4_pq",
        "outputId": "03c18f37-4679-45b3-cd92-13cdd98a9ff0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
      ],
      "metadata": {
        "id": "qO088kMi5AE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Base learners\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', SVC(probability=True)),\n",
        "    ('lr', LogisticRegression(max_iter=5000))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "stack_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, stack_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3lfG_A55BM3",
        "outputId": "530e717f-cc98-419b-dd59-9dbf0f156d5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q37. Train a Random Forest Classifier and print the top 5 most important features."
      ],
      "metadata": {
        "id": "Wfz23NYW5B0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Get indices of top 5 features\n",
        "indices = np.argsort(importances)[::-1][:5]\n",
        "\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "for i in indices:\n",
        "    print(f\"{feature_names[i]} : {importances[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV9QNnh95C83",
        "outputId": "f3166195-a54d-45ed-d491-f1dcfb32463b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "mean concave points : 0.1419344436315119\n",
            "worst concave points : 0.12713637963171595\n",
            "worst area : 0.11821685833472201\n",
            "mean concavity : 0.08055701642634591\n",
            "worst radius : 0.07797474929691814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score."
      ],
      "metadata": {
        "id": "OAJmWaRO5Dcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Bagging Classifier\n",
        "model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCYgps825Elf",
        "outputId": "a9f08ec9-a6d5-4211-85cb-5221fec57442"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
      ],
      "metadata": {
        "id": "R8kOknHH5ask"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Different max_depth values\n",
        "depth_values = [None, 2, 4, 6, 8, 10]\n",
        "\n",
        "for depth in depth_values:\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=depth,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"max_depth = {depth}, Accuracy = {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMlav1Q5b_P",
        "outputId": "dd8dae12-5ed7-4a56-a8aa-ec9a1ffd4c9c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth = None, Accuracy = 1.0\n",
            "max_depth = 2, Accuracy = 1.0\n",
            "max_depth = 4, Accuracy = 1.0\n",
            "max_depth = 6, Accuracy = 1.0\n",
            "max_depth = 8, Accuracy = 1.0\n",
            "max_depth = 10, Accuracy = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
        "performance."
      ],
      "metadata": {
        "id": "b9JNtzhG5cbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging with Decision Tree\n",
        "bag_dt = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Bagging with KNeighbors\n",
        "bag_knn = BaggingRegressor(\n",
        "    estimator=KNeighborsRegressor(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train models\n",
        "bag_dt.fit(X_train, y_train)\n",
        "bag_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "pred_dt = bag_dt.predict(X_test)\n",
        "pred_knn = bag_knn.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Bagging with Decision Tree:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_dt))\n",
        "print(\"R2 Score:\", r2_score(y_test, pred_dt))\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Bagging with KNeighbors:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred_knn))\n",
        "print(\"R2 Score:\", r2_score(y_test, pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY3V9WqU5drH",
        "outputId": "2cf4515c-20db-4a7c-c316-29a733402bb6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging with Decision Tree:\n",
            "MSE: 0.2568358813508342\n",
            "R2 Score: 0.8043214985798688\n",
            "----------------------------------------\n",
            "Bagging with KNeighbors:\n",
            "MSE: 1.0998197296736556\n",
            "R2 Score: 0.16206771653973295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
      ],
      "metadata": {
        "id": "lyQCPzsw5eBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset (Binary classification for ROC-AUC)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB5nfU1E5fdv",
        "outputId": "cf58ca97-fd60-49e6-c476-82223a48abff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9968400940623163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q42. Train a Bagging Classifier and evaluate its performance using cross-validation."
      ],
      "metadata": {
        "id": "ksMfxElt5f2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Create Bagging Classifier\n",
        "model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Perform Cross-Validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J01SluW5hDj",
        "outputId": "dec96f94-1fba-4735-9aa2-ac4ed6e03777"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy Scores: [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
            "Mean Accuracy: 0.9600000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q43. Train a Random Forest Classifier and plot the Precision-Recall curve."
      ],
      "metadata": {
        "id": "m8mPBs8r5iFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Load dataset (Binary classification)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute Precision-Recall values\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(f\"Precision-Recall Curve (AP = {avg_precision:.2f})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RhTNgMGH5jGD",
        "outputId": "2f9c9629-5006-4f1d-fc1e-589e6e9cb41a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
      ],
      "metadata": {
        "id": "Sl59GUyg5jhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Base models\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=5000))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "stack_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, stack_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qXJlW5y5k-S",
        "outputId": "6cae7b69-0026-4e97-96a5-a865935f073d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "zvjGIVje5md5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Different max_samples levels (bootstrap sample size)\n",
        "sample_levels = [0.5, 0.7, 0.9, 1.0]\n",
        "\n",
        "for sample in sample_levels:\n",
        "    model = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(),\n",
        "        n_estimators=100,\n",
        "        max_samples=sample,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"max_samples = {sample}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"R2 Score:\", r2)\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exJ-RNDK5ngl",
        "outputId": "639c53d6-a674-4120-8050-be108653a632"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_samples = 0.5\n",
            "MSE: 0.2625992591916903\n",
            "R2 Score: 0.7999304877402416\n",
            "----------------------------------------\n",
            "max_samples = 0.7\n",
            "MSE: 0.25850083535774365\n",
            "R2 Score: 0.8030530009568266\n",
            "----------------------------------------\n",
            "max_samples = 0.9\n",
            "MSE: 0.25797901212536184\n",
            "R2 Score: 0.8034505684134516\n",
            "----------------------------------------\n",
            "max_samples = 1.0\n",
            "MSE: 0.2568358813508342\n",
            "R2 Score: 0.8043214985798688\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}